llm:
  provider: openai # options: openai, anthropic, or gemini
  model: gpt-4.1-mini # options: gpt-4.1-mini, claude-haiku-4-5-20251001, gemini-2.5-flash
  temperature: 0

# Fine-grained task configuration (optional, uses llm default config above if not specified)
llm_tasks:
  # Answer generation (requires high quality)
  generation:
    provider: openai
    model: gpt-4.1-mini

  # Citation checking (uses llm default if not specified)
  # citation_check:
  #   provider: openai
  #   model: gpt-4.1-mini

  # Diagnostic analysis
  diagnosis:
    provider: openai
    model: gpt-4.1-mini

  # Tool strategy selection
  tool_strategy:
    provider: openai
    model: gpt-4.1-mini

  # GEO score evaluation
  geo_score:
    provider: openai
    model: gpt-4.1-mini

search:
  provider: chatnoir # tavily or chatnoir
  max_results: 10 # Number of search results to return (over-fetch to handle partial retrieval failures)

generator:
  method: in-context  # options: in-context, attr_evaluator
  max_snippet_length: 10000  # Maximum length (chars) of each search snippet to include in the prompt

html_browser:
  method: requests # options: requests, playwright

html_parser:
  method: trafilatura # options: bs4, markdown, html2text, newspaper, readability, trafilatura

data:
  mode: cw22 # online or cw22
  # Use relative path (relative to project root) or set as absolute path
  html_db_path: "./cache" # Path to store/retrieve HTML files
