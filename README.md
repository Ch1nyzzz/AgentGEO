# ğŸš€ AgentGEO: Autonomous Generative Engine Optimization Framework

**AgentGEO** is an autonomous agent framework designed to optimize web content for generative search engines (like ChatGPT, Perplexity, and SearchGPT). As search paradigms shift from traditional ranking to citation-based visibility, AgentGEO helps your content get **understood, adopted, and cited** by AI-powered search engines.

## ğŸŒŸ Key Features

- **ğŸ”„ Adaptive Optimization Loop**: Implements an `Assess â†’ Analyze â†’ Act` cycle that automatically evaluates citation performance, diagnoses issues, and applies fixes iteratively until success.

- **ğŸ§  Competitor Gap Analysis**: Integrates with search APIs (ChatNoir) to compare target pages against top-ranked competitors, identifying content gaps, tone issues, and structural deficiencies.

- **ğŸ› ï¸ Modular Tool System**:
  - **Content Tools**: Knowledge injection, style rewriting, persuasive writing strategies
  - **Technical Tools**: HTML semantic restructuring, metadata optimization
  - **AutoGEO Integration**: Includes AutoGEO paper methods via the `autogeo_rephrase` tool

- **ğŸ›¡ï¸ Type-Safe Architecture**: Built with **Pydantic** for robust schema validation, ensuring structured LLM outputs are accurate and reliable.

- **ğŸ”— Extensible Design**: Based on **LangChain** with a `Registry` pattern for easy custom tool registration.

- **âš¡ Flexible Citation Checking**:
  - LLM-based (fast)
  - Attribute Evaluator-based (accurate)
  - Hybrid modes for optimal performance

## ğŸ“– Table of Contents

- [Architecture Overview](#-architecture-overview)
- [Project Structure](#-project-structure)
- [Quick Start](#-quick-start)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
  - [Data Preparation](#data-preparation)
  - [Running Optimization](#running-optimization)
- [Configuration Guide](#-configuration-guide)
  - [Main Configuration](#main-configuration)
  - [Module Configuration](#module-configuration)
- [Usage Guide](#-usage-guide)
  - [Optimization Methods](#optimization-methods)
  - [Citation Checking Strategies](#citation-checking-strategies)
  - [Tool Extension](#tool-extension)
- [Scripts Reference](#-scripts-reference)
  - [Query Generation](#1-generate_queriespy)
  - [Optimization Runner](#2-run_optimizationpy)
- [FAQ](#-faq)
- [License](#-license)

## ğŸ—ï¸ Architecture Overview

AgentGEO simulates generative search engine behavior to optimize target web pages:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Optimization Loop                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. RETRIEVE  â†’ Search API (ChatNoir) â†’ Top 5 Results       â”‚
â”‚                                                              â”‚
â”‚  2. ASSESS    â†’ Mix Target Doc â†’ LLM Generation             â”‚
â”‚                â†’ Citation Check (LLM/Attr Evaluator)        â”‚
â”‚                                                              â”‚
â”‚  3. ANALYZE   â†’ Compare Target vs Competitors                â”‚
â”‚                â†’ Diagnose Issues (content/structure/tone)    â”‚
â”‚                                                              â”‚
â”‚  4. ACT       â†’ Select Tools from Registry                   â”‚
â”‚                â†’ Apply Optimizations                         â”‚
â”‚                                                              â”‚
â”‚  5. LOOP      â†’ Re-test until cited                          â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

1. **Retrieval**: Fetches top search results using ChatNoir API
2. **Assessment**: Generates AI responses and checks if target document is cited
3. **Analysis**: Compares target with competitors to identify gaps
4. **Action**: Applies registered tools to fix identified issues
5. **Iteration**: Repeats until citation success or max iterations reached

## ğŸ“‚ Project Structure

```
AgentGEO/
â”œâ”€â”€ geo_agent/                  # Core agent framework
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ optimizer.py        # Main optimization loop (the "Brain")
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ models.py           # Pydantic data models (WebPage, AnalysisResult, etc.)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ browser.py          # HTML content fetching
â”‚   â”‚   â”œâ”€â”€ loader.py           # HTML parsing and cleaning
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ generate/
â”‚   â”‚   â””â”€â”€ attr_first_then_gen.py  # Answer generation with attribution
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py         # Auto-loads and registers all tools
â”‚   â”‚   â”œâ”€â”€ registry.py         # Tool registration center
â”‚   â”‚   â”œâ”€â”€ content_tools.py    # Content optimization strategies
â”‚   â”‚   â””â”€â”€ tech_tools.py       # Technical optimization strategies
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ storage.py          # Data persistence utilities
â”‚   â””â”€â”€ config.yaml             # Module configuration (LLM, search, parsing)
â”‚
â”œâ”€â”€ attr_evaluator/             # Attribution evaluation module
â”‚   â”œâ”€â”€ run_dataset.py          # Main evaluation interface
â”‚   â”œâ”€â”€ run_script.py           # Script runner for subtasks
â”‚   â””â”€â”€ ...                     # Subtask-specific utilities
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ generate_queries.py     # Generate train/test queries from HTML
â”‚   â”œâ”€â”€ run_optimization.py     # Unified optimization runner
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                       # Data directory (create this)
â”‚   â”œâ”€â”€ input.parquet           # Input data (raw HTML + queries)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ outputs/                    # Output directory (auto-created)
â”‚   â”œâ”€â”€ optimized_html/         # Optimized web pages
â”‚   â”œâ”€â”€ reports/                # Evaluation reports
â”‚   â””â”€â”€ checkpoints/            # Progress checkpoints
â”‚
â”œâ”€â”€ optimization_config.yaml    # Main configuration file
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- API Keys:
  - **OpenAI API Key** (for LLM-based agent logic) or **Anthropic API Key** (for Claude) or **Google API Key** (for Gemini)
  - **ChatNoir API Key** (for competitor retrieval, optional if using mock mode)

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/your-username/autoGEO_reproduce.git
   cd autoGEO_reproduce/AgentGEO
   ```

2. **Create virtual environment and install dependencies**

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Set up environment variables**

   Create a `.env` file in the AgentGEO directory:

   ```env
   # Required: At least one LLM provider
   OPENAI_API_KEY=sk-proj-...
   # OR
   ANTHROPIC_API_KEY=sk-ant-...
   # OR
   GOOGLE_API_KEY=...

   # Optional: For competitor retrieval
   CHATNOIR_API_KEY=your_key_here
   ```

### Data Preparation

#### Using the Provided Dataset

The dataset is included in the repository:

```python
import pandas as pd

# Load the dataset
dataset = pd.read_parquet("data/input.parquet")
```

The dataset contains:
- `raw_html`: Original HTML content
- `train_queries`: Training queries (List[str])
- `test_queries`: Test queries (List[str])
- `url`: Document URL
- `doc_id`: Document identifier

#### Option 2: Generate Queries from Your Own Data

If you have raw HTML files without queries:

```bash
# Basic usage: generates 20 train + 20 test queries per document
python scripts/generate_queries.py --input data/my_data.parquet

# Custom query counts
python scripts/generate_queries.py \
    --input data/my_data.parquet \
    --train-count 30 \
    --test-count 10

# High concurrency for faster processing
python scripts/generate_queries.py \
    --input data/my_data.parquet \
    --concurrency 32
```

**Input Requirements**: Parquet file with `raw_html` column (and optionally `url`, `doc_id`)

**Output**: Original data + `train_queries` and `test_queries` columns

See [Scripts Reference](#scripts-reference) for detailed usage.

### Running Optimization

#### Basic Usage

```bash
# Run with default configuration (AgentGEO method)
python scripts/run_optimization.py

# Specify optimization method
python scripts/run_optimization.py --method agentgeo
python scripts/run_optimization.py --method autogeo
python scripts/run_optimization.py --method baseline

# Run all methods for comparison
python scripts/run_optimization.py --method all

# Custom configuration file
python scripts/run_optimization.py --config my_config.yaml

# Custom data and output paths
python scripts/run_optimization.py \
    --method agentgeo \
    --data data/input.parquet \
    --output-dir results/
```

#### Example Code

```python
from geo_agent.agent.optimizer import GEOAgent
from geo_agent.core.models import WebPage

# 1. Define your target web page
page = WebPage(
    url="https://example.com/deep-learning-guide",
    raw_html="<html>...</html>",
    cleaned_content="Deep learning is a subset of ML..."
)

# 2. Define queries users might ask
queries = [
    "What is the difference between DL and ML?",
    "Best resources to learn Deep Learning in 2024"
]

# 3. Initialize and run agent
agent = GEOAgent()
optimized_page = agent.optimize_page(page, queries)

# 4. Access results
print(optimized_page.cleaned_content)
print(f"Citation rate: {optimized_page.citation_rate}")
```

## âš™ï¸ Configuration Guide

### Main Configuration

The `optimization_config.yaml` file controls the entire optimization pipeline:

```yaml
# Optimization method selection
optimizer:
  method: "agentgeo"  # Options: autogeo, agentgeo, baseline, all

# AgentGEO configuration
agentgeo:
  config_path: "geo_agent/config.yaml"
  batch_size: 10
  max_concurrency: 4

  # Citation checking method
  citation_method: "llm"  # Options: llm, attr_evaluator, both

  # When using "both", choose strategy
  citation_composite_strategy: "any"  # Options: any, all, llm_primary, attr_primary

  # Attribute Evaluator settings
  attr_evaluator_config: null  # Path to custom config, or null for default
  use_fast_mode: true          # true = fast mode, false = full accuracy

  # Other settings
  enable_memory: true
  enable_history: true
  enable_autogeo_rephrase: true

# Data configuration
data:
  input_type: "parquet"
  input_path: "data/test_data.parquet"
  required_fields:
    - raw_html
    - train_queries
    - test_queries

# Output configuration
output:
  base_dir: "outputs"
  save_optimized_html: true
  save_evaluation: true
```

### Module Configuration

The `geo_agent/config.yaml` file configures individual components:

```yaml
# LLM configuration
llm:
  provider: openai  # Options: openai, anthropic, gemini
  model: gpt-4.1-mini
  temperature: 0

# Task-specific LLM settings (optional, overrides defaults)
llm_tasks:
  generation:
    provider: openai
    model: gpt-4.1-mini
  diagnosis:
    provider: openai
    model: gpt-4.1-mini

# Search engine configuration
search:
  provider: chatnoir  # Options: tavily, chatnoir
  max_results: 10

# HTML parsing configuration
html_parser:
  method: trafilatura  # Options: bs4, markdown, html2text, trafilatura

# Data mode
data:
  mode: cw22  # Options: online, cw22
  html_db_path: "../../experiments/cache"
```

## ğŸ“š Usage Guide

### Optimization Methods

AgentGEO supports three optimization approaches:

#### 1. **AgentGEO** (Recommended)

Our autonomous agent method with adaptive optimization loop.

```yaml
optimizer:
  method: "agentgeo"

agentgeo:
  citation_method: "attr_evaluator"
  use_fast_mode: true
  enable_memory: true
  enable_history: true
```

**Best for**: Production use, high-quality optimization

#### 2. **AutoGEO**

Baseline method from the AutoGEO paper.

```yaml
optimizer:
  method: "autogeo"

autogeo:
  dataset_name: "GEO-Bench"
  engine_llm: "claude-haiku-4-5-20251001"
  rule_path: null
```

**Best for**: Comparison with paper results, rule-based optimization

#### 3. **Baseline**

GEO-Bench's 9 optimization strategies.

```yaml
optimizer:
  method: "baseline"

baseline:
  provider: "openai"
  model: "gpt-4.1-mini"
  methods: null  # null = all 9 methods, or specify: ["cite_sources", "authoritative"]
```

**Best for**: Benchmarking, ablation studies

### Citation Checking Strategies

AgentGEO offers multiple citation checking methods with different speed/accuracy trade-offs:

| Method | Speed | Accuracy | Use Case |
|--------|-------|----------|----------|
| `llm` | Fast | Medium | Rapid prototyping, large-scale processing |
| `attr_evaluator (fast)` | Medium | High | **Production (Recommended)** |
| `attr_evaluator (full)` | Slow | Highest | High-quality requirements, small batches |
| `both (any)` | Slow | High | Maximize recall |
| `both (all)` | Slow | Highest | Maximize precision (strictest) |
| `both (attr_primary)` | Slow | Highest | Accuracy-focused |
| `both (llm_primary)` | Medium | Medium | Balanced speed/accuracy |

**Configuration Examples:**

```yaml
# Fast mode (LLM only)
agentgeo:
  citation_method: "llm"

# Accurate mode (Attribute Evaluator - Recommended)
agentgeo:
  citation_method: "attr_evaluator"
  use_fast_mode: true

# Maximum accuracy mode
agentgeo:
  citation_method: "attr_evaluator"
  use_fast_mode: false

# Hybrid mode - maximize recall
agentgeo:
  citation_method: "both"
  citation_composite_strategy: "any"

# Hybrid mode - maximize precision
agentgeo:
  citation_method: "both"
  citation_composite_strategy: "all"
```

### Tool Extension

AgentGEO's modular architecture makes it easy to add custom optimization strategies.

#### Adding a New Tool

1. **Create a new tool file** in `geo_agent/tools/`, e.g., `persuasion_tools.py`

2. **Define the tool with Pydantic schema:**

```python
# geo_agent/tools/persuasion_tools.py
from pydantic import BaseModel, Field
from .registry import registry

class EmotionalHookInput(BaseModel):
    content: str = Field(..., description="Target content")
    emotion: str = Field(..., description="Emotion to evoke (e.g., 'urgency', 'curiosity')")

def add_emotional_hook(content: str, emotion: str) -> str:
    """Add emotional hooks to content to increase engagement."""
    # Implementation logic here
    return modified_content

# Register the tool
registry.register(add_emotional_hook, EmotionalHookInput)
```

3. **Import the tool** in `geo_agent/tools/__init__.py`:

```python
from . import persuasion_tools
```

4. **The agent will automatically discover and use the tool** when appropriate.

## ğŸ› ï¸ Scripts Reference

### 1. `generate_queries.py`

Generates train/test queries from HTML documents using LLM.

#### Features

- âœ… Checkpoint-based resume (auto-saves progress)
- âœ… Concurrent processing (multi-threaded)
- âœ… Auto-generates `doc_id` if missing
- âœ… Flexible configuration (query counts, LLM settings)
- âœ… Handles empty/invalid HTML gracefully

#### Usage

```bash
# Basic usage
python scripts/generate_queries.py --input data/input.parquet

# Custom query counts
python scripts/generate_queries.py \
    --input data/input.parquet \
    --train-count 30 \
    --test-count 10

# High concurrency
python scripts/generate_queries.py \
    --input data/input.parquet \
    --concurrency 32

# Test mode (first 3 documents only)
python scripts/generate_queries.py \
    --input data/input.parquet \
    --limit 3

# Reset checkpoint and start fresh
python scripts/generate_queries.py \
    --input data/input.parquet \
    --reset
```

#### Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `--input` | str | Required | Input parquet file (must have `raw_html` column) |
| `--output` | str | `{input}_with_queries.parquet` | Output file path |
| `--train-count` | int | 20 | Number of training queries per document |
| `--test-count` | int | 20 | Number of test queries per document |
| `--config` | str | `query_generator/config.yaml` | LLM config file |
| `--seed` | int | 42 | Random seed |
| `--limit` | int | None | Limit number of documents (for testing) |
| `--reset` | flag | False | Reset checkpoint and start fresh |
| `--concurrency` | int | 8 | Number of concurrent threads |

### 2. `run_optimization.py`

Unified optimization runner supporting multiple methods.

#### Usage

```bash
# Use AgentGEO
python scripts/run_optimization.py --method agentgeo

# Use AutoGEO
python scripts/run_optimization.py --method autogeo

# Use GEO-Bench baseline
python scripts/run_optimization.py --method baseline

# Run all methods for comparison
python scripts/run_optimization.py --method all

# Custom configuration
python scripts/run_optimization.py --config my_config.yaml

# Custom data and output
python scripts/run_optimization.py \
    --method agentgeo \
    --data data/input.parquet \
    --output-dir results/
```

## â“ FAQ

### Q: How do I check optimization progress?

**A:** The script outputs real-time progress in the format `[Completed/Total] Status doc_id | Stats`. Checkpoints are automatically saved.

### Q: What if the process gets interrupted?

**A:** Simply re-run the same command. The script automatically resumes from the checkpoint.

### Q: Which citation method should I use?

**A:**
- For production: `citation_method: "attr_evaluator"` with `use_fast_mode: true`
- For prototyping: `citation_method: "llm"`
- For maximum accuracy: `citation_method: "attr_evaluator"` with `use_fast_mode: false`

### Q: How can I speed up processing?

**A:**
1. Increase concurrency: `max_concurrency: 8`
2. Use faster LLM models (e.g., GPT-4 Turbo, Claude Haiku)
3. Use LLM citation checking: `citation_method: "llm"`
4. Reduce batch size if hitting rate limits

### Q: Can I use my own LLM?

**A:** Yes! Configure in `geo_agent/config.yaml`:

```yaml
llm:
  provider: openai  # or anthropic, gemini
  model: your-model-name
  temperature: 0
```

Ensure the corresponding API key is set in `.env`.

### Q: How do I customize optimization tools?

**A:** See the [Tool Extension](#tool-extension) section. Create a new Python file in `geo_agent/tools/`, define your tool with a Pydantic schema, register it, and import in `__init__.py`.

### Q: What data format is required?

**A:** Parquet files with these fields:
- **Required**: `raw_html` (str)
- **For optimization**: `train_queries` (List[str]), `test_queries` (List[str])
- **Optional**: `url` (str), `doc_id` (str)

Use `generate_queries.py` to add queries if you only have `raw_html`.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Need Help?** Open an issue on GitHub or check the configuration examples in `optimization_config.yaml`.

**Contributing:** Contributions are welcome! Please submit pull requests or create issues for bugs/feature requests.
